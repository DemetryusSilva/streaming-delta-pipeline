# Real-Time Clickstream Pipeline with Delta Lake ğŸš€

Este projeto demonstra um pipeline de engenharia de dados ponta a ponta para processar eventos de cliques (logs) em tempo real usando a arquitetura de Lakehouse.

## ğŸ›  Tecnologias
- **Linguagem:** Python (PySpark)
- **Processamento:** Spark Structured Streaming
- **Storage:** Delta Lake (ACID Transactions)
- **Infra:** Docker

## ğŸ“ˆ O que este projeto faz?
1. **GeraÃ§Ã£o de Dados:** Um script Python simula cliques de usuÃ¡rios em um e-commerce.
2. **Streaming:** O Spark monitora a chegada de novos arquivos e os processa instantaneamente.
3. **AgregaÃ§Ã£o:** O pipeline calcula a contagem de eventos por janela de tempo (Windowing).
4. **PersistÃªncia:** Os dados sÃ£o salvos em formato **Delta**, permitindo auditoria e versionamento (Time Travel).

## ğŸš€ Como rodar
1. Suba o container: `docker-compose up -d`
2. Instale as dependÃªncias: `pip install -r requirements.txt`
3. Inicie o gerador: `python app/generator.py`
4. Em outro terminal, inicie o pipeline: `python app/pipeline.py`

## ğŸ“Š Estrutura Delta
Os dados sÃ£o salvos em `data/delta/`, onde vocÃª pode consultar as tabelas Bronze (Raw) e Gold (Aggregated).
